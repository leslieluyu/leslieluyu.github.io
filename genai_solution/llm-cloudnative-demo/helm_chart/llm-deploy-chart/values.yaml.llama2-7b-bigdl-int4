kubernetesClusterDomain: cluster.local
llmDeploy:
  llmDeployDemo:
    env:
      framework: bigdl-llm-transformers
      llamaCppThreads: "16"
      metricPort: "8090"
      modelDtype: int4
      modelName: llama2-7b
      modelPath: /models/Llama-2-7b-hf
      ompNumThreads: "16"
      svcPort: "8000"
    image:
      repository: docker201904/llm-inference-api
      tag: v2_metrics
    resources:
      limits:
        cpu: "16"
        memory: 6Gi
      requests:
        cpu: "16"
        memory: 6Gi
  nodeSelector:
    llmdemo: "true"
  ports:
  - name: service
    nodePort: 30021
    port: 8080
    targetPort: 8000
  - name: metric-service
    nodePort: 30022
    port: 8090
    targetPort: 8090
  replicas: 1
  type: NodePort
