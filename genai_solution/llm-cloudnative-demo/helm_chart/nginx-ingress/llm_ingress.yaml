apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: llm-ingress
  annotations:
    nginx.org/lb-method: "round_robin"
    nginx.org/max-conns: "1"
      #nginx.ingress.kubernetes.io/proxy-buffer-size: "16k" 
      #nginx.ingress.kubernetes.io/proxy-buffers-number: "4"
      #nginx.ingress.kubernetes.io/proxy-max-temp-file-size: "1024m"
    nginx.org/proxy-requests: "4"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-next-upstream-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-connect-timeout: '600'
    nginx.ingress.kubernetes.io/proxy-send-timeout: '600'
    nginx.ingress.kubernetes.io/proxy-read-timeout: '600'
spec:
  ingressClassName: nginx
  rules:
    - host: llm.intel.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: llm-deploy
                port:
                  number: 8080
                    #maxConns: 1

